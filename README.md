# SensusAI

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Go](https://img.shields.io/badge/Go-1.21-00ADD8.svg)
![Python](https://img.shields.io/badge/Python-3.11-3776AB.svg)

**AI-Powered Intelligent Monitoring Platform**

*Latince "sensus" (algÄ±, sezgi) - Sensing Anomalies, Delivering Insights*

[Ã–zellikler](#-Ã¶zellikler) â€¢ [Kurulum](#-kurulum) â€¢ [KullanÄ±m](#-kullanÄ±m) â€¢ [Mimari](#-mimari) â€¢ [KatkÄ±da Bulunma](#-katkÄ±da-bulunma)

</div>

---

## ğŸ“ AÃ§Ä±klama

**SensusAI**, sistem uyarÄ±larÄ±nÄ± (alerts) ve metriklerini toplamak, saklamak ve yapay zeka ile analiz etmek iÃ§in geliÅŸtirilmiÅŸ yÃ¼ksek performanslÄ± bir **mikroservis mimarisidir**. Prometheus AlertManager ile entegre Ã§alÄ±ÅŸÄ±r, metrik anomalilerini tespit eder ve LLM (Large Language Model) kullanarak kÃ¶k neden analizi yapar.

AdÄ± Latince "sensus" (algÄ±, his, sezgi) kelimesinden gelir - sistemlerinizin altÄ±ncÄ± hissi gibi Ã§alÄ±ÅŸÄ±r.

### ğŸ¯ Temel Hedefler

- **Real-time Monitoring**: AnlÄ±k sistem metriklerini ve uyarÄ±larÄ±nÄ± toplama
- **Anomali Tespiti**: Machine Learning ile otomatik anomali tespiti (Isolation Forest)
- **AkÄ±llÄ± Analiz**: LLM destekli kÃ¶k neden analizi ve Ã§Ã¶zÃ¼m Ã¶nerileri
- **YÃ¼ksek Performans**: Async processing, connection pooling, stream processing
- **Ã–lÃ§eklenebilirlik**: Mikroservis mimarisi ile horizontal ve vertical scaling

---

## âœ¨ Ã–zellikler

### ğŸ” Monitoring & Data Collection
- âœ… Prometheus AlertManager webhook entegrasyonu
- âœ… REST API ile Ã¶zel metrik toplama
- âœ… PostgreSQL'de persistent storage
- âœ… Redis Streams ile real-time data processing
- âœ… Pre-configured Grafana dashboards
- âœ… Prometheus alert rules (30+ alerts)

### ğŸ¤– AI/ML Capabilities
- âœ… **Isolation Forest** algoritmasÄ± ile anomali tespiti
- âœ… **Ollama/Llama2** LLM ile kÃ¶k neden analizi
- âœ… Otomatik model training ve versiyonlama
- âœ… Scheduled model retraining (APScheduler)
- âœ… Confidence score hesaplama
- âœ… Model performance evaluation

### ğŸ“Š Visualization & Monitoring
- âœ… Grafana dashboards (Prometheus & PostgreSQL datasources)
- âœ… Prometheus metrics export
- âœ… Real-time alert tracking
- âœ… AI analysis result visualization
- âœ… Auto-provisioned dashboards

### ğŸš€ Performance & Reliability
- âœ… Connection pooling (PostgreSQL, Redis)
- âœ… Async/non-blocking I/O
- âœ… Health check endpoints
- âœ… Auto-retry mechanisms
- âœ… Graceful error handling

### ğŸ” Security & Authentication
- âœ… JWT token-based authentication
- âœ… Redis-based rate limiting (sliding window)
- âœ… Scope-based permissions
- âœ… Request throttling per endpoint
- âœ… Correlation ID tracking

### ğŸ§ª Testing & Quality
- âœ… Comprehensive unit tests (80%+ coverage)
- âœ… Integration tests
- âœ… Pytest with async support
- âœ… Go test suite with benchmarks
- âœ… CI/CD pipeline (GitHub Actions)

### ğŸš¢ Deployment & DevOps
- âœ… Docker & Docker Compose
- âœ… Kubernetes manifests with HPA
- âœ… Production-ready configurations
- âœ… Automated setup scripts
- âœ… Backup & restore utilities
- âœ… Multi-environment support (dev/prod)

---

## ğŸ—ï¸ Mimari

```
External Sources â†’ Collector (Go) â†’ PostgreSQL + Redis Streams
                                           â†“
                                    AI Service (Python)
                                      â†“           â†“
                                 ML Detector   LLM Analyzer
                                      â†“           â†“
                                    PostgreSQL (Results)
                                           â†“
                                  Grafana Dashboards
```

**DetaylÄ± mimari dokÃ¼mantasyon iÃ§in**: [ARCHITECTURE.md](./ARCHITECTURE.md)

### Servisler

| Servis | Port | Teknoloji | AÃ§Ä±klama |
|--------|------|-----------|----------|
| **Collector** | 8080 | Go/Gin | Metrik ve alert toplama servisi |
| **AI Service** | 8082 | Python/FastAPI | ML/LLM analiz servisi |
| **PostgreSQL** | 5432 | PostgreSQL 15 | Ana veritabanÄ± |
| **Redis** | 6379 | Redis 7 | Message streaming & cache |
| **Ollama** | 11434 | Ollama/Llama2 | LLM inference engine |
| **Prometheus** | 9090 | Prometheus | Metrics collection |
| **Grafana** | 3000 | Grafana | Visualization dashboards |

---

## ğŸ“‹ Gereksinimler

### Sistem Gereksinimleri

| BileÅŸen | Minimum | Ã–nerilen |
|---------|---------|----------|
| **CPU** | 4 cores | 8 cores |
| **RAM** | 8 GB | 16 GB |
| **Disk** | 20 GB | 50 GB SSD |
| **OS** | Linux/macOS/Windows with WSL2 | Ubuntu 22.04 LTS |

### YazÄ±lÄ±m Gereksinimleri

- **Docker**: 20.10.x veya Ã¼zeri
- **Docker Compose**: 2.x veya Ã¼zeri
- **Git**: 2.x veya Ã¼zeri

> **Not**: Ollama servisi iÃ§in GPU desteÄŸi opsiyoneldir ancak Ã¶nerilir (daha hÄ±zlÄ± LLM inference).

---

## ğŸš€ Kurulum

### HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Ã–nerilen)

```bash
# Otomatik kurulum scripti
git clone https://github.com/your-username/SensusAI.git
cd SensusAI
./scripts/setup.sh
```

veya

```bash
# Makefile ile
make quickstart
```

### Manuel Kurulum

### 1. Depoyu KlonlayÄ±n

```bash
git clone https://github.com/your-username/SensusAI.git
cd SensusAI
```

### 2. Environment DeÄŸiÅŸkenlerini Kontrol Edin

Docker Compose, default deÄŸiÅŸkenleri kullanÄ±r. Ã–zelleÅŸtirme iÃ§in `.env` dosyasÄ± oluÅŸturabilirsiniz:

```bash
# .env (opsiyonel)
POSTGRES_USER=kam_user
POSTGRES_PASSWORD=kam_password
POSTGRES_DB=kam_alerts
REDIS_ADDR=redis:6379
OLLAMA_URL=http://ollama:11434
GRAFANA_ADMIN_PASSWORD=kam_password
```

### 3. Docker Container'larÄ± BaÅŸlatÄ±n

```bash
# TÃ¼m servisleri build et ve baÅŸlat
docker-compose up --build -d

# LoglarÄ± izle
docker-compose logs -f

# Belirli bir servisin logunu izle
docker-compose logs -f ai-service
```

### 4. Ollama Model'ini Ä°ndirin

Ollama container'Ä± baÅŸladÄ±ktan sonra Llama2 modelini indirin:

```bash
docker exec -it sensusai-ollama-1 ollama pull llama2
```

> **Ä°lk kullanÄ±mda**: Model indirme iÅŸlemi ~4GB veri indireceÄŸi iÃ§in birkaÃ§ dakika sÃ¼rebilir.

### 5. Servislerin Durumunu Kontrol Edin

```bash
# TÃ¼m container'larÄ±n durumunu kontrol et
docker-compose ps

# Health check'leri test et
curl http://localhost:8080/health  # Collector
curl http://localhost:8082/health  # AI Service
curl http://localhost:9090/-/healthy  # Prometheus
curl http://localhost:3000/api/health  # Grafana
```

**Beklenen Ã‡Ä±ktÄ±:**
```
NAME                        STATUS    PORTS
sensusai-collector-1      running   0.0.0.0:8080->8080/tcp
sensusai-ai-service-1     running   0.0.0.0:8082->8082/tcp
sensusai-postgresql-1     running   0.0.0.0:5432->5432/tcp
sensusai-redis-1          running   0.0.0.0:6379->6379/tcp
sensusai-ollama-1         running   0.0.0.0:11434->11434/tcp
sensusai-prometheus-1     running   0.0.0.0:9090->9090/tcp
sensusai-grafana-1        running   0.0.0.0:3000->3000/tcp
```

---

## ğŸ” Authentication (Yeni!)

SensusAI JWT token-based authentication kullanÄ±r.

### Token Alma

```bash
# Basic auth ile login
curl -X POST http://localhost:8082/api/v1/auth/token \
  -u admin:secret

# Response
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

### Token ile API KullanÄ±mÄ±

```bash
# Token ile korumalÄ± endpoint'e eriÅŸim
curl http://localhost:8082/api/v1/analysis/latest \
  -H "Authorization: Bearer <your-token>"
```

**Default KullanÄ±cÄ±lar:**
- Username: `admin` / Password: `secret` (tÃ¼m yetkiler)
- Username: `user` / Password: `secret` (sadece okuma)

> âš ï¸ Production'da bu ÅŸifreleri deÄŸiÅŸtirin!

---

## ğŸ“– KullanÄ±m

### 1. Metrik GÃ¶nderme

REST API ile manuel metrik gÃ¶nderimi:

```bash
curl -X POST http://localhost:8080/api/v1/metrics \
  -H "Content-Type: application/json" \
  -d '{
    "metric_name": "cpu_usage",
    "metric_value": 85.5,
    "labels": {
      "host": "server-1",
      "environment": "production"
    }
  }'
```

**Response:**
```json
{
  "status": "processed"
}
```

### 2. Alert GÃ¶nderme (Prometheus AlertManager Format)

```bash
curl -X POST http://localhost:8080/api/v1/alerts \
  -H "Content-Type: application/json" \
  -d '[{
    "labels": {
      "alertname": "HighCPUUsage",
      "severity": "critical",
      "instance": "server-1"
    },
    "annotations": {
      "description": "CPU usage is above 90% for 5 minutes",
      "summary": "High CPU detected on server-1"
    },
    "startsAt": "2024-02-07T10:00:00Z",
    "generatorURL": "http://prometheus:9090/graph?g0.expr=cpu_usage"
  }]'
```

**Response:**
```json
{
  "status": "processed",
  "count": 1
}
```

### 3. AI Analiz SonuÃ§larÄ±nÄ± GÃ¶rÃ¼ntÃ¼leme

Son analiz sonuÃ§larÄ±nÄ± REST API ile sorgulayÄ±n:

```bash
curl http://localhost:8082/api/v1/analysis/latest
```

**Response:**
```json
[
  {
    "id": "123",
    "alert_id": "456",
    "analysis_type": "llm_analysis",
    "model_name": "llama2",
    "analysis_data": {
      "root_cause": "Memory leak in application process",
      "mitigation": "Restart the affected service and monitor memory usage",
      "analysis": "Critical CPU threshold exceeded due to memory pressure"
    },
    "confidence_score": 0.85,
    "created_at": "2024-02-07T10:05:00Z"
  }
]
```

### 4. Grafana Dashboard'larÄ±na EriÅŸim

1. **Grafana'ya giriÅŸ yapÄ±n:**
   - URL: http://localhost:3000
   - Username: `admin`
   - Password: `kam_password`

2. **Datasources'Ä± kontrol edin:**
   - Configuration â†’ Data Sources
   - Prometheus ve PostgreSQL datasource'larÄ± otomatik yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r

3. **Dashboard oluÅŸturun:**
   - **Prometheus datasource** ile:
     - `sensus_alerts_received_total` - Gelen alert sayÄ±sÄ±
     - `sensus_metrics_received_total` - Gelen metrik sayÄ±sÄ±
     - `sensus_processing_duration_seconds` - Ä°ÅŸlem sÃ¼releri

   - **PostgreSQL datasource** ile:
     ```sql
     -- Son 24 saatteki alertler
     SELECT created_at, alert_name, severity, status
     FROM alerts
     WHERE created_at > NOW() - INTERVAL '24 hours'
     ORDER BY created_at DESC;

     -- AI analiz sonuÃ§larÄ±
     SELECT a.alert_name, a.severity,
            r.analysis_type, r.confidence_score, r.created_at
     FROM ai_analysis_results r
     JOIN alerts a ON r.alert_id = a.id
     ORDER BY r.created_at DESC
     LIMIT 50;
     ```

### 5. Prometheus Targets'Ä± Kontrol Etme

- URL: http://localhost:9090/targets
- TÃ¼m target'larÄ±n **UP** durumunda olduÄŸunu kontrol edin

### 6. Database'e Direkt EriÅŸim

PostgreSQL'e baÄŸlanmak iÃ§in:

```bash
docker exec -it sensusai-postgresql-1 psql -U kam_user -d kam_alerts
```

**Ã–rnek Sorgular:**

```sql
-- Son 10 metrik
SELECT * FROM metrics ORDER BY timestamp DESC LIMIT 10;

-- Son 10 alert
SELECT * FROM alerts ORDER BY created_at DESC LIMIT 10;

-- Anomali tespit sonuÃ§larÄ±
SELECT * FROM ai_analysis_results
WHERE analysis_type = 'anomaly_detection'
ORDER BY created_at DESC LIMIT 10;

-- LLM analiz sonuÃ§larÄ±
SELECT
    a.alert_name,
    a.severity,
    r.analysis_data->>'root_cause' as root_cause,
    r.analysis_data->>'mitigation' as mitigation,
    r.confidence_score
FROM ai_analysis_results r
JOIN alerts a ON r.alert_id = a.id
WHERE r.analysis_type = 'llm_analysis'
ORDER BY r.created_at DESC;
```

---

## ğŸ”§ KonfigÃ¼rasyon

### Collector Service Configuration

`collector/main.go` dosyasÄ±nda aÅŸaÄŸÄ±daki environment deÄŸiÅŸkenleri kullanÄ±lÄ±r:

| DeÄŸiÅŸken | VarsayÄ±lan | AÃ§Ä±klama |
|----------|-----------|----------|
| `DB_HOST` | postgresql | PostgreSQL host |
| `DB_USER` | kam_user | PostgreSQL kullanÄ±cÄ± adÄ± |
| `DB_PASSWORD` | kam_password | PostgreSQL ÅŸifresi |
| `DB_NAME` | kam_alerts | VeritabanÄ± adÄ± |
| `REDIS_ADDR` | redis:6379 | Redis adresi |

### AI Service Configuration

`ai-service/app/config.py` dosyasÄ±nda aÅŸaÄŸÄ±daki ayarlar yapÄ±lÄ±r:

| DeÄŸiÅŸken | VarsayÄ±lan | AÃ§Ä±klama |
|----------|-----------|----------|
| `REDIS_URL` | redis://redis:6379 | Redis connection URL |
| `POSTGRES_HOST` | postgres | PostgreSQL host |
| `POSTGRES_USER` | kam_user | PostgreSQL kullanÄ±cÄ± adÄ± |
| `POSTGRES_PASSWORD` | kam_password | PostgreSQL ÅŸifresi |
| `POSTGRES_DB` | kam_alerts | VeritabanÄ± adÄ± |
| `OLLAMA_HOST` | ollama | Ollama host |
| `OLLAMA_PORT` | 11434 | Ollama port |

### Prometheus AlertManager Webhook Configuration

Prometheus AlertManager'Ä± SensusAI'ye yÃ¶nlendirmek iÃ§in:

```yaml
# alertmanager.yml
route:
  receiver: 'sensusai-webhook'

receivers:
  - name: 'sensusai-webhook'
    webhook_configs:
      - url: 'http://collector:8080/api/v1/alerts'
        send_resolved: true
```

---

## ğŸ§ª Test

### Otomatik Test Suite

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
make test

# Sadece AI service testleri
make test-ai

# Sadece Collector testleri
make test-collector

# Coverage report ile
cd ai-service && pytest --cov=app --cov-report=html
```

**Test Ä°statistikleri:**
- AI Service: 20+ test, 80%+ coverage
- Collector: 12+ test, 75%+ coverage
- Total: 32+ test, 78%+ coverage

### Linting

```bash
# TÃ¼m linting
make lint

# Otomatik dÃ¼zeltme
make lint-fix
```

### Manuel Test Script'i

Otomatik test iÃ§in sample metrik ve alert gÃ¶nderin:

```bash
#!/bin/bash

# Test metrikleri gÃ¶nder
for i in {1..10}; do
  cpu_value=$((RANDOM % 100))
  curl -X POST http://localhost:8080/api/v1/metrics \
    -H "Content-Type: application/json" \
    -d "{
      \"metric_name\": \"cpu_usage\",
      \"metric_value\": $cpu_value,
      \"labels\": {\"host\": \"test-server-$i\"}
    }"
  echo "Sent metric: cpu_usage=$cpu_value"
  sleep 1
done

# Test alert'i gÃ¶nder
curl -X POST http://localhost:8080/api/v1/alerts \
  -H "Content-Type: application/json" \
  -d '[{
    "labels": {
      "alertname": "TestAlert",
      "severity": "warning"
    },
    "annotations": {
      "description": "This is a test alert"
    },
    "startsAt": "2024-02-07T10:00:00Z"
  }]'

echo -e "\nâœ… Test verileri gÃ¶nderildi!"
echo "AI analiz sonuÃ§larÄ±nÄ± gÃ¶rmek iÃ§in:"
echo "curl http://localhost:8082/api/v1/analysis/latest"
```

DosyayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
chmod +x test_data.sh
./test_data.sh
```

### Log Ä°zleme

Servislerin iÅŸlem durumunu izleyin:

```bash
# AI Service log'larÄ±nÄ± izle (anomali tespiti ve LLM analiz)
docker-compose logs -f ai-service

# Collector log'larÄ±nÄ± izle (gelen metrik/alert)
docker-compose logs -f collector

# Redis consumer log'larÄ±nÄ± izle
docker-compose logs -f ai-service | grep "Consumer"
```

---

## ğŸ› Troubleshooting

### Problem: Servisler baÅŸlamÄ±yor

**Ã‡Ã¶zÃ¼m:**
```bash
# Container'larÄ± durdur ve temizle
docker-compose down -v

# Yeniden build et
docker-compose up --build -d

# Log'larÄ± kontrol et
docker-compose logs
```

### Problem: PostgreSQL baÄŸlantÄ± hatasÄ±

**Belirti:** `connection refused` veya `database does not exist`

**Ã‡Ã¶zÃ¼m:**
```bash
# PostgreSQL container'Ä±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin ol
docker-compose ps postgresql

# Health check durumu
docker exec sensusai-postgresql-1 pg_isready -U kam_user

# Manuel baÄŸlantÄ± testi
docker exec -it sensusai-postgresql-1 psql -U kam_user -d kam_alerts -c "SELECT 1;"
```

### Problem: Ollama model yÃ¼klenmedi

**Belirti:** LLM analiz hatalarÄ±

**Ã‡Ã¶zÃ¼m:**
```bash
# Ollama container'Ä±na baÄŸlan
docker exec -it sensusai-ollama-1 bash

# Mevcut modelleri listele
ollama list

# Model yoksa indir
ollama pull llama2

# Model indirme durumunu kontrol et
curl http://localhost:11434/api/tags
```

### Problem: Redis connection timeout

**Ã‡Ã¶zÃ¼m:**
```bash
# Redis'in Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin ol
docker exec sensusai-redis-1 redis-cli ping
# Beklenen: PONG

# Redis stream kontrolÃ¼
docker exec sensusai-redis-1 redis-cli XINFO STREAM metrics:raw
```

### Problem: AI Service mesaj consume etmiyor

**Belirti:** Metrikler gelmiyor ancak database'e yazÄ±lmÄ±yor

**Ã‡Ã¶zÃ¼m:**
```bash
# AI Service log'larÄ±nÄ± kontrol et
docker-compose logs ai-service | grep "Consumer"

# Redis stream'i manuel kontrol et
docker exec sensusai-redis-1 redis-cli XLEN metrics:raw
# Mesaj sayÄ±sÄ± gÃ¶rÃ¼nmeli

# Consumer group durumu
docker exec sensusai-redis-1 redis-cli XINFO GROUPS metrics:raw

# AI Service'i yeniden baÅŸlat
docker-compose restart ai-service
```

### Problem: DÃ¼ÅŸÃ¼k performans

**Ã‡Ã¶zÃ¼m:**
```bash
# Resource kullanÄ±mÄ±nÄ± kontrol et
docker stats

# Ollama iÃ§in daha fazla memory ayÄ±r (docker-compose.yml)
# deploy.resources.limits.memory: 8G

# PostgreSQL connection pool artÄ±r (ai-service/app/database.py)
# max_size: 30

# Redis pool size artÄ±r (collector/main.go)
# PoolSize: 30
```

---

## ğŸ›‘ Servisleri Durdurma

### GeÃ§ici Durdurma

```bash
# TÃ¼m servisleri durdur (data korunur)
docker-compose stop

# Tekrar baÅŸlat
docker-compose start
```

### Tamamen KaldÄ±rma

```bash
# Container'larÄ± ve network'Ã¼ sil (volume'ler korunur)
docker-compose down

# Volume'leri de sil (TÃœM VERÄ°LER SÄ°LÄ°NÄ°R!)
docker-compose down -v
```

### Belirli Bir Servisi Yeniden BaÅŸlatma

```bash
docker-compose restart ai-service
docker-compose restart collector
```

---

## ğŸ“Š Metriks ve Monitoring

### Toplanan Prometheus Metrics

#### Collector Metrics (8080/metrics)
- `sensus_alerts_received_total` - Toplam gelen alert sayÄ±sÄ±
- `sensus_metrics_received_total` - Toplam gelen metrik sayÄ±sÄ±
- `sensus_processing_duration_seconds` - Request iÅŸlem sÃ¼resi (histogram)

#### KullanÄ±m:
```promql
# Alert alma hÄ±zÄ± (son 5 dakika)
rate(sensus_alerts_received_total[5m])

# 95. percentile iÅŸlem sÃ¼resi
histogram_quantile(0.95, sensus_processing_duration_seconds_bucket)

# Metrik toplama hÄ±zÄ±
rate(sensus_metrics_received_total[5m])
```

---

## ğŸ”’ GÃ¼venlik NotlarÄ±

> âš ï¸ **Ã–NEMLÄ°**: Bu kurulum **development/test** ortamlarÄ± iÃ§indir. Production kullanÄ±mÄ± iÃ§in:

- [ ] TÃ¼m default ÅŸifreleri deÄŸiÅŸtirin
- [ ] Environment deÄŸiÅŸkenlerini secrets manager'a taÅŸÄ±yÄ±n (Vault, AWS Secrets Manager)
- [ ] TLS/SSL etkinleÅŸtirin (PostgreSQL, Redis, HTTP)
- [ ] Network segmentasyonu yapÄ±n
- [ ] Rate limiting ekleyin
- [ ] API authentication/authorization implementi yapÄ±n (JWT, OAuth2)
- [ ] Firewall kurallarÄ± yapÄ±landÄ±rÄ±n
- [ ] Container'larÄ± non-root user ile Ã§alÄ±ÅŸtÄ±rÄ±n
- [ ] Image vulnerability scanning yapÄ±n (Trivy, Clair)
- [ ] Audit logging ekleyin

---

## ğŸ› ï¸ Makefile KomutlarÄ±

```bash
make help              # TÃ¼m komutlarÄ± listele
make build             # Docker image'larÄ± build et
make up                # Servisleri baÅŸlat
make down              # Servisleri durdur
make logs              # LoglarÄ± gÃ¶ster
make test              # Testleri Ã§alÄ±ÅŸtÄ±r
make lint              # Kodu kontrol et
make health-check      # Servis saÄŸlÄ±ÄŸÄ±nÄ± kontrol et
make send-test-data    # Test verisi gÃ¶nder
make db-backup         # Database yedekle
make db-restore        # Database geri yÃ¼kle
make clean             # Cleanup yap
make quickstart        # Her ÅŸeyi baÅŸlat
```

### Utility Scripts

```bash
./scripts/setup.sh     # Otomatik kurulum
./scripts/backup.sh    # Database backup
./scripts/restore.sh   # Database restore
./scripts/monitor.sh   # CanlÄ± monitoring
```

---

## â˜¸ï¸ Kubernetes Deployment

```bash
# Namespace oluÅŸtur
kubectl apply -f k8s/base/namespace.yaml

# TÃ¼m kaynaklarÄ± deploy et
kubectl apply -f k8s/base/

# Veya Kustomize ile
kubectl apply -k k8s/overlays/prod/

# Durumu kontrol et
kubectl get pods -n sensusai
kubectl get svc -n sensusai

# Logs
kubectl logs -f deployment/ai-service -n sensusai

# Scaling
kubectl scale deployment collector -n sensusai --replicas=5
```

**Auto-scaling (HPA) otomatik olarak yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r:**
- Collector: 2-10 replicas (CPU 70%, Memory 80%)
- AI Service: 2-5 replicas (CPU 70%, Memory 80%)

DetaylÄ± bilgi: [k8s/README.md](./k8s/README.md)

---

## ğŸš¢ Production Deployment

```bash
# Production compose ile
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Veya Makefile ile
make deploy-prod
```

**Production Ã¶zellikleri:**
- Resource limits ve reservations
- Replicated services (2x collector, 2x ai-service)
- Enhanced logging
- Auto-restart policies
- Performance tuning

DetaylÄ± bilgi: [DEPLOYMENT.md](./DEPLOYMENT.md)

---

## ğŸ”„ CI/CD Pipeline

GitHub Actions ile otomatik CI/CD:

**`.github/workflows/ci.yml`:**
- âœ… Python ve Go testleri
- âœ… Linting (black, flake8, golangci-lint)
- âœ… Code coverage (Codecov)
- âœ… Docker image build
- âœ… Security scanning (Trivy)

**`.github/workflows/deploy.yml`:**
- âœ… Container registry push (GHCR)
- âœ… Staging deployment (main branch)
- âœ… Production deployment (tags)

---

## ğŸ“š Ek Kaynaklar

### DokÃ¼mantasyon
- **Mimari DokÃ¼mantasyon**: [ARCHITECTURE.md](./ARCHITECTURE.md)
- **Deployment Guide**: [DEPLOYMENT.md](./DEPLOYMENT.md)
- **Contributing Guide**: [CONTRIBUTING.md](./CONTRIBUTING.md)
- **Kubernetes Guide**: [k8s/README.md](./k8s/README.md)

### API & Monitoring
- **API DokÃ¼mantasyonu**: http://localhost:8082/docs (FastAPI auto-generated)
- **Prometheus UI**: http://localhost:9090
- **Grafana**: http://localhost:3000
- **Prometheus Alerts**: http://localhost:9090/alerts

### Teknoloji DokÃ¼mantasyonlarÄ±
- [Go Gin Framework](https://gin-gonic.com/docs/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [PostgreSQL](https://www.postgresql.org/docs/)
- [Redis Streams](https://redis.io/docs/data-types/streams/)
- [Ollama](https://ollama.ai/docs)
- [Scikit-learn Isolation Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)

---

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip edin:

1. Fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add amazing feature'`)
4. Branch'inizi push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

### GeliÅŸtirme KurallarÄ±
- Code style: Go (gofmt), Python (black, isort)
- Commit message format: Conventional Commits
- Test coverage: Minimum %80
- Documentation: Her yeni feature iÃ§in dokÃ¼mantasyon ekleyin

---

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---

## ğŸ‘¥ Yazarlar

- **SensusAI Development Team**

---

## ğŸ™ TeÅŸekkÃ¼rler

- [Prometheus](https://prometheus.io/) - Monitoring sistemi
- [Grafana](https://grafana.com/) - Visualization
- [Ollama](https://ollama.ai/) - LLM inference
- [PostgreSQL](https://www.postgresql.org/) - Database
- [Redis](https://redis.io/) - Streaming & caching

---

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in:
- GitHub Issues: [Create an issue](https://github.com/your-username/SensusAI/issues)
- Email: support@sensusai.dev

---

<div align="center">

**SensusAI** ile sisteminizi akÄ±llÄ±ca izleyin! ğŸš€

Made with â¤ï¸ by SensusAI Team

</div>
